<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jay&#39;s Notes</title>
    <link>/post/</link>
    <description>Recent content in Posts on Jay&#39;s Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>R Markdown in Vim</title>
      <link>/post/2019/04/05/r-markdown-revisited/</link>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/04/05/r-markdown-revisited/</guid>
      <description>Two ways to render R Markdown documents Render R Markdown from Vim (without opening R) Render R Markdown (and send email) from R    Two ways to render R Markdown documents I saw this tweet a couple of days ago and decided to look for ways to use R Markdown more at work.
TIL you can embed a &amp;quot;code download&amp;quot; button in an HTML #rmarkdown doc so that users can click to download your source .</description>
    </item>
    
    <item>
      <title>Home and home score difference</title>
      <link>/post/2019/02/04/home-and-home-score-difference/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/04/home-and-home-score-difference/</guid>
      <description>## Adding missing grouping variables: `season_opp` # score diff between 1st and 2nd games # too many to show! move on to next p &amp;lt;- df_hnh %&amp;gt;% ungroup() %&amp;gt;% ggplot(aes(x = game_order, y = score_diff)) + geom_point(aes(group = season_opp, colour = season_opp)) #+ #geom_line(aes(group = season_opp, colour = season_opp)) + print(p) # score change distribution df_hnh_wide &amp;lt;- df_hnh %&amp;gt;% ungroup() %&amp;gt;% select(Season, Opponent_School, game_order, score_diff) %&amp;gt;% spread(key = game_order, value = score_diff) %&amp;gt;% mutate(turnaround = game_2 - game_1) df_hnh_wide %&amp;gt;% arrange(desc(turnaround)) %&amp;gt;% head(10) ## # A tibble: 10 x 5 ## Season Opponent_School game_1 game_2 turnaround ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 2006 Virginia -4 45 49 ## 2 1993 Wake Forest -26 18 44 ## 3 1989 Virginia -23 18 41 ## 4 1997 Florida State -13 28 41 ## 5 1998 Florida State 8 48 40 ## 6 1970 Clemson 5 44 39 ## 7 2014 Wake Forest -6 33 39 ## 8 1965 Wake Forest -22 16 38 ## 9 1997 Wake Forest -24 14 38 ## 10 1985 Clemson -2 34 36 p &amp;lt;- df_hnh_wide %&amp;gt;% mutate(RWera = ifelse(Season &amp;gt;= 2004, TRUE, FALSE)) %&amp;gt;% ggplot(aes(x = turnaround)) + geom_density(aes(colour = factor(RWera))) </description>
    </item>
    
    <item>
      <title>Coping with worst loss at home</title>
      <link>/post/2019/01/13/worst-performance-at-home-sweet-dome/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/13/worst-performance-at-home-sweet-dome/</guid>
      <description>It’s been a tough weekend, not least because Tar Heels lost at home. Sometimes I feel like I’m vested too much in the outcome of the Heel’s basketball games, and if my emotional rollercoaster the rest of the weekend gives any clue, I probably am, just a litttle bit. I tried to shake it off, yet it wasn’t particularly easy, not only because we lost at home, but because the loss was the worst one at home under Roy Williams.</description>
    </item>
    
    <item>
      <title>First 8 games results</title>
      <link>/post/2018/12/01/first-8-games-results/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/12/01/first-8-games-results/</guid>
      <description># Load libraries for R suppressPackageStartupMessages(library(ggplot2)) suppressPackageStartupMessages(library(dplyr)) suppressPackageStartupMessages(library(uncmbb)) # dataset n &amp;lt;- 8 df_n &amp;lt;- unc %&amp;gt;% group_by(Season) %&amp;gt;% arrange(Game_Date) %&amp;gt;% top_n(-n, Game_Date) a &amp;lt;- df_n %&amp;gt;% group_by(Season) %&amp;gt;% summarize(wins = sum(Result == &amp;quot;W&amp;quot;), losses = sum(Result == &amp;quot;L&amp;quot;)) %&amp;gt;% left_join(mbb_champ_season(unc), by = &amp;quot;Season&amp;quot;) b &amp;lt;- a %&amp;gt;% ggplot(aes(x = losses)) + geom_bar() df_pre12 &amp;lt;- unc %&amp;gt;% group_by(Season) %&amp;gt;% filter(as.numeric(substring(Game_Date, 6, 7)) %in% c(10, 11)) %&amp;gt;% summarize(games = n(), wins = sum(Result == &amp;quot;W&amp;quot;), losses = sum(Result == &amp;quot;L&amp;quot;)) b &amp;lt;- df_pre12 %&amp;gt;% ggplot(aes(x = losses)) + geom_bar() </description>
    </item>
    
    <item>
      <title>SQL, Visualization, R, and Python</title>
      <link>/post/2018/11/03/plotting-101-r-vs-python/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/11/03/plotting-101-r-vs-python/</guid>
      <description>Setup Load libraries Read data  Bar chart Simple frequency Grouped frequency  Line chart Simple sequence Grouped sequence    Not long ago, I saw a thread in my tweeter feed that was talking about what should be the first thing that a data scientist student learns. There were two answers that made sense to me: SQL and visualization.
SQL, because, one needs to be able to get desired data from somewhere, and for the most part in an industry setting at least, that somewhere is typically some form of databases (e.</description>
    </item>
    
    <item>
      <title>Home game streak</title>
      <link>/post/2018/10/06/home-game-streak/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/10/06/home-game-streak/</guid>
      <description>The schedule for the 2018-2019 UNC MBB season has been out, and I ran into a blog post that said something about some teams getting preferable schedules than others, in that those lucky teams get to play three consecutive games at home and in some case, not having to face the same number of consecutive games on the road. I remembered UNC team had a touch streak last season, having to play 3 in a row on the road, and with the current 15 member system (since 2010), such imbalance in schedule is bound to happen eventually.</description>
    </item>
    
    <item>
      <title>Vim, vim-slime, and screen</title>
      <link>/post/2018/10/06/vim-and-slime/</link>
      <pubDate>Sat, 06 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/10/06/vim-and-slime/</guid>
      <description>As much as I love using RStudio for everything1, there are times when I can’t really use it, i.e., for some projects at work in which I need to log in to some servers and do work there (i.e., on the server side). Using RStudio server would do it, I think, but it’s not an option at the moment. For a long time, I’ve been trying to establish a good working data analysis workflow that I can follow in those situations.</description>
    </item>
    
    <item>
      <title>GNU Make for Data Analysis Workflow Management</title>
      <link>/post/2018/08/26/gnu-make-for-workflow-manager/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/08/26/gnu-make-for-workflow-manager/</guid>
      <description>I’ve finally started using GNU make as a data analysis workflow management tool. I knew it existed as a software “build” tool, and although I always thought Makefile1 sound pretty cool, I never actually had to use it, not just as a build tool, but also as a data analysis workflow management tool.
It started with @thosjleepr’s tweet that showed up in my feed:
 Inspired by @carlislerainey, I’ve added some code to my intro #make tutorial that visualizes the makefile’s dependency graph natively in R using #ggraph.</description>
    </item>
    
    <item>
      <title>Home sweet dome</title>
      <link>/post/2018/08/05/home-sweet-dome/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/08/05/home-sweet-dome/</guid>
      <description>I ran into a post on the Tar Heel Blog (THB) that talks about the Tar Heel’s home court advantage in recent years. Since it’s been a while since I wrote anything about UNCMBB, I thought it’d be a great topic to write on here too, looking at how great the teams have played on home court1 in recent years. And maybe I’ll look at how Duke has played on their home court too during the same time period just because.</description>
    </item>
    
    <item>
      <title>My old coding products</title>
      <link>/post/2018/07/27/my-old-coding-products/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/07/27/my-old-coding-products/</guid>
      <description>Lately I’ve been thinking about why I care much about everything R and sharing the joy of using R, which deserves its own post. Much of it has to do with how I did and did not get a proper training in coding suitable for data analysis in the past, but as I looked back on my personal coding history, I came across hundreds of code files that I wrote in the past1.</description>
    </item>
    
  </channel>
</rss>