---
title: Random Forest Revisited
author: Jay
date: '2018-05-11'
slug: random-forest-revisited
categories: []
tags: []
draft: true
---



<div id="hypothetical-setting" class="section level2">
<h2>Hypothetical setting</h2>
<ul>
<li>Objective: binary classification</li>
<li>N = 5M observations</li>
<li>p = 10 variables (5 categorical and 5 continuous variables)</li>
<li>ntree = 100 (model will not be adversely affected if ntree is too big)</li>
<li>mtry = number of predictors to consider at each split (fixed or determined by resampling (10-fold cv)</li>
</ul>
</div>
<div id="bootstrap-samples-for-each-tree" class="section level2">
<h2>Bootstrap samples for each tree</h2>
<ul>
<li>Bootstrap samples (sampling with replacement) of same size as the original data (N) is taken at each tree.</li>
<li>This results in about 1/3 of N (hence approx. 1.6M) samples never being chosen for each tree. This is called out of bag (OOB) samples.</li>
<li>This OOB samples are used for:
<ul>
<li>Unbiased estimate of test set error
<ul>
<li>Theoretically, there’s no need for cv or a separate test set to get an unbiased estimate of the test set error, as it’s estimated internally during tree constructions.</li>
<li>OOB error estimate is the proportion of times (over all x_is in overall OOB samples) that predicted class is different from the true class for sample x<sub>i</sub>. Note the prediction for x<sub>i</sub> is obtained using only the trees that did not have x<sub>i</sub> in bootstrap sample.</li>
</ul></li>
<li>Estimate of variable importance: see variablem importance section below.</li>
</ul></li>
</ul>
</div>
<div id="split-criteria" class="section level2">
<h2>Split criteria</h2>
<ul>
<li>At each split, the mtry number of predictors are randomly selected (to de-correlate the trees), and a splitting variable is obtained.
<ul>
<li>The spliting variable is the one that results in the most homogeneous descendents (nodes).</li>
</ul></li>
<li>Once the best mtry is fixed (or obtained via resampling, such as cv), caret (randomForest too?) fits the final model using the best mtry and save to finalModel.</li>
</ul>
</div>
<div id="categorical-variable-treatment-various-encoding-methods" class="section level2">
<h2>Categorical variable treatment (various encoding methods)</h2>
<ul>
<li>Has implications in variable importance!
<ul>
<li>How to “aggregate” one-hot encoded feature importance!?</li>
</ul></li>
<li>Has implications in grid search step!
<ul>
<li>Grid search for best mtry (in k-fold cv) might result in different result for mtry</li>
</ul></li>
<li>Various encoding methods
<ul>
<li>Label encoding (integer encoding/string indexing)
<ul>
<li>Simple hashing/lookup (dog –&gt; 0, cat –&gt; 1, etc.)</li>
<li>If not the categorical variable is not ordinal, arbitrary indexing can be problematic (e.g., why dog (=0) &lt; cat (=1)).
<ul>
<li>Python/Pyspark solves this issue by providing an ordering structure (i.e., 0 to the most frequent item, 1 to the second frequent, and so on).</li>
</ul></li>
</ul></li>
<li>One-hot encoding (dummy variable)
<ul>
<li>Default method in caret (seems for both character and factor variables)
<ul>
<li>Default method in R maybe?</li>
</ul></li>
<li>Is one-hot encoding bad? See [<a href="http://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/" class="uri">http://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/</a>]</li>
</ul></li>
<li>Binary encoding
<ul>
<li>Seems interesting, but see this:</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="continuous-variable-treatment-binning-vs.raw" class="section level2">
<h2>Continuous variable treatment (binning vs. raw)</h2>
<ul>
<li>For customers subscription based analyses, it seems customary to bin some continuous variables such as tenures into bins, instead of using raw numbers.
<ul>
<li>Does this make your model rather robust?</li>
</ul></li>
</ul>
</div>
<div id="variable-importance-interpretations" class="section level2">
<h2>Variable importance interpretations</h2>
<ul>
<li>From the original randomForest package (and not from caret)
<ul>
<li>Mean decrease in accuracy (by permutation test, type = 1)
<ul>
<li>How’s permutation done?</li>
<li>Randomly permuting the values of each predictor for the OOB sample of one predictor at a time for each tree.</li>
<li>The difference in predictive performance between the non-permted sample and the permuted sample for each preditor is recorded and aggregated acoross the entire forest.</li>
</ul></li>
<li>Mean decrease in impurity (no need for additional test, type = 2): total decrease in impurities resulting from using variable k as a splitter, averaged over all trees.
<ul>
<li>“… is often very consistent with the permutation importance measure”, from [<a href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp" class="uri">https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp</a>]</li>
</ul></li>
</ul></li>
<li>What am I getting from caret::varImp vs. randomForest::importance?
<ul>
<li>By default, it seems both caret::varImp and randomForest::importance gives the impurity measure (type = 2)</li>
<li>randomForest::importance(caret_model_object<span class="math inline">\(fit\)</span>finalModel) gives the MeanDescreaseGini importance values, and so does caret::varImp(caret_model_object$fit, scale = FALSE)!!</li>
</ul></li>
<li>Variable selection/importance quality?
<ul>
<li>Relevant to different categorical encoding method (e.g., one-hot encoding results in individual level vs. label encoding just one)</li>
<li>See Strobl et al. [<a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25" class="uri">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25</a>]
<ul>
<li>RF favors continuous variables and categoricals with many levels
<ul>
<li>So if all variables are categoricals with relatively small number of levels, prob ok for now</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="class-imbalance" class="section level2">
<h2>Class imbalance</h2>
<ul>
<li>See <a href="https://dpmartin42.github.io/posts/r/imbalanced-classes-part-1" class="uri">https://dpmartin42.github.io/posts/r/imbalanced-classes-part-1</a></li>
</ul>
</div>
