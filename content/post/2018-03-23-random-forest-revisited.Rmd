---
title: Random Forest Revisited
author: Jay
date: '2018-05-11'
slug: random-forest-revisited
categories: []
tags: []
draft: true
---

## Hypothetical setting
- Objective: binary classification
- N = 5M observations
- p = 10 variables (5 categorical and 5 continuous variables)
- ntree = 100 (model will not be adversely affected if ntree is too big)
- mtry = number of predictors to consider at each split (fixed or determined by resampling (10-fold cv)

## Bootstrap samples for each tree
- Bootstrap samples (sampling with replacement) of same size as the original data (N) is taken at each tree.
- This results in about 1/3 of N (hence approx. 1.6M) samples never being chosen for each tree. This is called out of bag (OOB) samples.
- This OOB samples are used for:
    - Unbiased estimate of test set error
        - Theoretically, there's no need for cv or a separate test set to get an unbiased estimate of the test set error, as it's estimated internally during tree constructions. 
        - OOB error estimate is the proportion of times (over all x_is in overall OOB samples) that predicted class is different from the true class for sample x~i~. Note the prediction for x~i~ is obtained using only the trees that did not have x~i~ in bootstrap sample. 
    - Estimate of variable importance: see variablem importance section below.
    
## Split criteria
- At each split, the mtry number of predictors are randomly selected (to de-correlate the trees), and a splitting variable is obtained.
    - The spliting variable is the one that results in the most homogeneous descendents (nodes).
- Once the best mtry is fixed (or obtained via resampling, such as cv), caret (randomForest too?) fits the final model using the best mtry and save to finalModel.

## Categorical variable treatment (various encoding methods)
- Has implications in variable importance!
    - How to "aggregate" one-hot encoded feature importance!?
- Has implications in grid search step!
    - Grid search for best mtry (in k-fold cv) might result in different result for mtry
- Various encoding methods  
    - Label encoding (integer encoding/string indexing)
        - Simple hashing/lookup (dog --> 0, cat --> 1, etc.)
        - If not the categorical variable is not ordinal, arbitrary indexing can be problematic (e.g., why dog (=0) < cat (=1)).
            - Python/Pyspark solves this issue by providing an ordering structure (i.e., 0 to the most frequent item, 1 to the second frequent, and so on). 
    - One-hot encoding (dummy variable)
        - Default method in caret (seems for both character and factor variables)
            - Default method in R maybe?
        - Is one-hot encoding bad? See [http://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/]
    - Binary encoding
        - Seems interesting, but see this: 

## Continuous variable treatment (binning vs. raw)
- For customers subscription based analyses, it seems customary to bin some continuous variables such as tenures into bins, instead of using raw numbers.
    - Does this make your model rather robust?

## Variable importance interpretations
- From the original randomForest package (and not from caret)
    - Mean decrease in accuracy (by permutation test, type = 1)
        - How's permutation done?
        - Randomly permuting the values of each predictor for the OOB sample of one predictor at a time for each tree.
        - The difference in predictive performance between the non-permted sample and the permuted sample for each preditor is recorded and aggregated acoross the entire forest.
    - Mean decrease in impurity (no need for additional test, type = 2): total decrease in impurities resulting from using variable k as a splitter, averaged over all trees. 
        - "... is often very consistent with the permutation importance measure", from [https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp]
- What am I getting from caret::varImp vs. randomForest::importance?
    - By default, it seems both caret::varImp and randomForest::importance gives the impurity measure (type = 2)
    - randomForest::importance(caret_model_object$fit$finalModel) gives the MeanDescreaseGini importance values, and so does caret::varImp(caret_model_object$fit, scale = FALSE)!!
- Variable selection/importance quality?
    - Relevant to different categorical encoding method (e.g., one-hot encoding results in individual level vs. label encoding just one)
    - See Strobl et al. [https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25]
        - RF favors continuous variables and categoricals with many levels
          - So if all variables are categoricals with relatively small number of levels, prob ok for now
  
## Class imbalance
- See https://dpmartin42.github.io/posts/r/imbalanced-classes-part-1
